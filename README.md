# Mini BAGLS Dataset Project

## Project Overview
This project involves working with a mini version of the Benchmark for Automatic Glottis Segmentation (BAGLS) dataset. The tasks covered include exploring the dataset and converting images from RGB to grayscale. This work helps to develop an understanding of handling and preprocessing image data for potential applications in computer vision tasks.

## Dataset Description
The Benchmark for Automatic Glottis Segmentation (BAGLS) dataset is a comprehensive collection of laryngeal video frames, designed for training and benchmarking automatic glottis segmentation methods. For the purposes of this project, a smaller subset of the BAGLS dataset is used, providing an opportunity to perform basic image processing tasks efficiently.

### Contents of the Mini BAGLS Dataset
- **Images**: RGB images that capture laryngeal frames.
- **Masks**: Corresponding segmentation masks that highlight the regions of interest (e.g., the glottis area).
- **Meta File**: A metadata file providing additional information about each image, such as annotations, frame details, or other relevant attributes.

## Objectives
1. **Familiarize with Image Datasets**: Understand the structure and components of a real-world image dataset.
2. **Image Processing**: Perform an image transformation from RGB to grayscale using common programming libraries.

## Setup and Requirements

### Prerequisites
- Python (3.11 recommended)
- Basic knowledge of image processing libraries such as OpenCV or PIL

### Libraries
Make sure you have the following libraries installed:
- `numpy`
- `opencv-python`
- `matplotlib` (for image visualization)

- ### Contributing
If you would like to contribute to this project, feel free to fork the repository and submit a pull request. Suggestions and improvements are welcome!

### Contact
For any questions or issues, please contact vishakh.cheruparambath@fau.de

You can install these libraries using:
```bash prompt
pip install numpy opencv-python matplotlib

